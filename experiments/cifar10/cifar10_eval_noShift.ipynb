{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "691557dd-f0fb-45a8-89db-7e754653d123",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/holystore01/LABS/iaifi_lab/Users/sambt/mamba/envs/torch_gpu/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset, ConcatDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms.v2 as v2\n",
    "from copy import deepcopy\n",
    "import sys\n",
    "sys.path.append(\"/n/home11/sambt/phlab-neurips25\")\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "from models.litmodels import SimCLRModel\n",
    "from models.networks import CustomResNet, MLP\n",
    "from models.losses import MMDLoss, RBF\n",
    "from data.datasets import CIFAR10Dataset\n",
    "from data.cifar import CIFAR5MDataset\n",
    "import data.data_utils as dutils\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, top_k_accuracy_score\n",
    "from utils.plotting import make_corner\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d4a6f17-bcf8-40b5-a239-d20faa874bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/holystore01/LABS/iaifi_lab/Users/sambt/mamba/envs/torch_gpu/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'encoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['encoder'])`.\n",
      "/n/holystore01/LABS/iaifi_lab/Users/sambt/mamba/envs/torch_gpu/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'projector' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['projector'])`.\n",
      "/n/holystore01/LABS/iaifi_lab/Users/sambt/mamba/envs/torch_gpu/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'classifier' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['classifier'])`.\n"
     ]
    }
   ],
   "source": [
    "N_cifar5m_load = 100_000\n",
    "cifar = CIFAR10Dataset(\"resnet50\",num_workers=2,batch_size=1024,exclude_classes=[])\n",
    "cifar_train_dataset = cifar.train_dataset\n",
    "cifar_test_dataset = cifar.test_dataset\n",
    "cifar5m_full = CIFAR5MDataset(\"resnet50\",[0],[(None,N_cifar5m_load)],grayscale=False,exclude_classes=[])\n",
    "\n",
    "cifar_train_loader = DataLoader(cifar_train_dataset,batch_size=512,shuffle=True)\n",
    "cifar_test_loader = DataLoader(cifar_test_dataset,batch_size=512,shuffle=True)\n",
    "cifar5m_loader = DataLoader(cifar5m_full,batch_size=512,shuffle=True)\n",
    "\n",
    "classes = np.arange(10)\n",
    "#checkpoints = {\n",
    "#    0:\"/n/home11/sambt/phlab-neurips25/runs/cifar10_simCLR_ResNet50_T0.1_dim4_exclude0/lightning_logs/2xpzevgs/checkpoints/epoch=3-step=352.ckpt\",\n",
    "#    1:\"/n/home11/sambt/phlab-neurips25/runs/cifar10_simCLR_ResNet50_T0.1_dim4_exclude1/lightning_logs/phformo7/checkpoints/epoch=3-step=352.ckpt\",\n",
    "#    2:\"/n/home11/sambt/phlab-neurips25/runs/cifar10_simCLR_ResNet50_T0.1_dim4_exclude2/lightning_logs/7qzpzkw2/checkpoints/epoch=4-step=440.ckpt\",\n",
    "#    3:\"/n/home11/sambt/phlab-neurips25/runs/cifar10_simCLR_ResNet50_T0.1_dim4_exclude3/lightning_logs/1tg0w3bd/checkpoints/epoch=4-step=440.ckpt\",\n",
    "#    4:\"/n/home11/sambt/phlab-neurips25/runs/cifar10_simCLR_ResNet50_T0.1_dim4_exclude4/lightning_logs/q7lmidvn/checkpoints/epoch=4-step=440.ckpt\",\n",
    "#    5:\"/n/home11/sambt/phlab-neurips25/runs/cifar10_simCLR_ResNet50_T0.1_dim4_exclude5/lightning_logs/fykocd4q/checkpoints/epoch=8-step=792.ckpt\",\n",
    "#    6:\"/n/home11/sambt/phlab-neurips25/runs/cifar10_simCLR_ResNet50_T0.1_dim4_exclude6/lightning_logs/n5eq4qyw/checkpoints/epoch=4-step=440.ckpt\",\n",
    "#    7:\"/n/home11/sambt/phlab-neurips25/runs/cifar10_simCLR_ResNet50_T0.1_dim4_exclude7/lightning_logs/516e1a20/checkpoints/epoch=4-step=440.ckpt\",\n",
    "#    8:\"/n/home11/sambt/phlab-neurips25/runs/cifar10_simCLR_ResNet50_T0.1_dim4_exclude8/lightning_logs/r74quvbx/checkpoints/epoch=4-step=440.ckpt\",\n",
    "#    9:\"/n/home11/sambt/phlab-neurips25/runs/cifar10_simCLR_ResNet50_T0.1_dim4_exclude9/lightning_logs/uxa5naeo/checkpoints/epoch=6-step=616.ckpt\"\n",
    "#}\n",
    "checkpoints = {\n",
    "    1:\"/n/home11/sambt/phlab-neurips25/runs/cifar10_simCLR_ResNet50_T0.1_withClassifier_dim4_exclude1/lightning_logs/a9v4e8zh/checkpoints/epoch=4-step=440.ckpt\",\n",
    "    2:\"/n/home11/sambt/phlab-neurips25/runs/cifar10_simCLR_ResNet50_T0.1_withClassifier_dim4_exclude2/lightning_logs/rlzxkflo/checkpoints/epoch=5-step=528.ckpt\",\n",
    "    3:\"/n/home11/sambt/phlab-neurips25/runs/cifar10_simCLR_ResNet50_T0.1_withClassifier_dim4_exclude3/lightning_logs/wi6idr9q/checkpoints/epoch=5-step=528.ckpt\",\n",
    "    4:\"/n/home11/sambt/phlab-neurips25/runs/cifar10_simCLR_ResNet50_T0.1_withClassifier_dim4_exclude4/lightning_logs/nfmxrtyd/checkpoints/epoch=3-step=352.ckpt\",\n",
    "    5:\"/n/home11/sambt/phlab-neurips25/runs/cifar10_simCLR_ResNet50_T0.1_withClassifier_dim4_exclude5/lightning_logs/lhxchpq6/checkpoints/epoch=6-step=616.ckpt\",\n",
    "    6:\"/n/home11/sambt/phlab-neurips25/runs/cifar10_simCLR_ResNet50_T0.1_withClassifier_dim4_exclude6/lightning_logs/pvt7snek/checkpoints/epoch=2-step=264.ckpt\"\n",
    "}\n",
    "classes = sorted(list(checkpoints.keys()))\n",
    "\n",
    "models = {l:SimCLRModel.load_from_checkpoint(checkpoints[l]).to(device) for l in classes}\n",
    "outdirs = {}\n",
    "for label in classes:\n",
    "    outdir = f\"embeddings_noShift_spaceWithClassifier/cifar_excludeClass{label}/\"\n",
    "    os.makedirs(outdir,exist_ok=True)\n",
    "    outdirs[label] = outdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdc65a31-c5ff-4233-8897-f4409ac6df72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [03:37<00:00,  2.22s/it]\n",
      "100%|██████████| 20/20 [00:43<00:00,  2.17s/it]\n",
      "100%|██████████| 196/196 [06:59<00:00,  2.14s/it]\n"
     ]
    }
   ],
   "source": [
    "embeds = {l:[] for l in classes}\n",
    "labels = {l:[] for l in classes}\n",
    "for batch in tqdm(cifar_train_loader):\n",
    "    x,labs = batch\n",
    "    for l in classes:\n",
    "        with torch.no_grad():\n",
    "            embeds[l].append(models[l].encoder(x.to(device)).cpu().numpy())\n",
    "        labels[l].append(labs.numpy())\n",
    "for l in classes:\n",
    "    np.savez(f\"{outdirs[l]}/cifar10_train.npz\",\n",
    "             data=np.concatenate(embeds[l]),\n",
    "             labels=np.concatenate(labels[l]))\n",
    "del embeds, labels\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "embeds = {l:[] for l in classes}\n",
    "labels = {l:[] for l in classes}\n",
    "for batch in tqdm(cifar_test_loader):\n",
    "    x,labs = batch\n",
    "    for l in classes:\n",
    "        with torch.no_grad():\n",
    "            embeds[l].append(models[l].encoder(x.to(device)).cpu().numpy())\n",
    "        labels[l].append(labs.numpy())\n",
    "for l in classes:\n",
    "    np.savez(f\"{outdirs[l]}/cifar10_test.npz\",\n",
    "             data=np.concatenate(embeds[l]),\n",
    "             labels=np.concatenate(labels[l]))\n",
    "del embeds, labels\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "embeds = {l:[] for l in classes}\n",
    "labels = {l:[] for l in classes}\n",
    "for batch in tqdm(cifar5m_loader):\n",
    "    x,labs = batch\n",
    "    for l in classes:\n",
    "        with torch.no_grad():\n",
    "            embeds[l].append(models[l].encoder(x.to(device)).cpu().numpy())\n",
    "        labels[l].append(labs.numpy())\n",
    "for l in classes:\n",
    "    np.savez(f\"{outdirs[l]}/cifar5m_N{N_cifar5m_load}.npz\",\n",
    "             data=np.concatenate(embeds[l]),\n",
    "             labels=np.concatenate(labels[l]))\n",
    "del embeds, labels\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f5e1dc-c364-427f-b534-020ac4a41200",
   "metadata": {},
   "source": [
    "# eval on cifar 10.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbc3605a-b326-42f8-91ce-e2ec6ad20d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classes = np.arange(10)\n",
    "#checkpoints = {\n",
    "#    0:\"/n/home11/sambt/phlab-neurips25/runs/cifar10_simCLR_ResNet50_T0.1_dim4_exclude0/lightning_logs/2xpzevgs/checkpoints/epoch=3-step=352.ckpt\",\n",
    "#    1:\"/n/home11/sambt/phlab-neurips25/runs/cifar10_simCLR_ResNet50_T0.1_dim4_exclude1/lightning_logs/phformo7/checkpoints/epoch=3-step=352.ckpt\",\n",
    "#    2:\"/n/home11/sambt/phlab-neurips25/runs/cifar10_simCLR_ResNet50_T0.1_dim4_exclude2/lightning_logs/7qzpzkw2/checkpoints/epoch=4-step=440.ckpt\",\n",
    "#    3:\"/n/home11/sambt/phlab-neurips25/runs/cifar10_simCLR_ResNet50_T0.1_dim4_exclude3/lightning_logs/1tg0w3bd/checkpoints/epoch=4-step=440.ckpt\",\n",
    "#    4:\"/n/home11/sambt/phlab-neurips25/runs/cifar10_simCLR_ResNet50_T0.1_dim4_exclude4/lightning_logs/q7lmidvn/checkpoints/epoch=4-step=440.ckpt\",\n",
    "#    5:\"/n/home11/sambt/phlab-neurips25/runs/cifar10_simCLR_ResNet50_T0.1_dim4_exclude5/lightning_logs/fykocd4q/checkpoints/epoch=8-step=792.ckpt\",\n",
    "#    6:\"/n/home11/sambt/phlab-neurips25/runs/cifar10_simCLR_ResNet50_T0.1_dim4_exclude6/lightning_logs/n5eq4qyw/checkpoints/epoch=4-step=440.ckpt\",\n",
    "#    7:\"/n/home11/sambt/phlab-neurips25/runs/cifar10_simCLR_ResNet50_T0.1_dim4_exclude7/lightning_logs/516e1a20/checkpoints/epoch=4-step=440.ckpt\",\n",
    "#    8:\"/n/home11/sambt/phlab-neurips25/runs/cifar10_simCLR_ResNet50_T0.1_dim4_exclude8/lightning_logs/r74quvbx/checkpoints/epoch=4-step=440.ckpt\",\n",
    "#    9:\"/n/home11/sambt/phlab-neurips25/runs/cifar10_simCLR_ResNet50_T0.1_dim4_exclude9/lightning_logs/uxa5naeo/checkpoints/epoch=6-step=616.ckpt\"\n",
    "#}\n",
    "\n",
    "checkpoints = {\n",
    "    1:\"/n/home11/sambt/phlab-neurips25/runs/cifar10_simCLR_ResNet50_T0.1_withClassifier_dim4_exclude1/lightning_logs/a9v4e8zh/checkpoints/epoch=4-step=440.ckpt\",\n",
    "    2:\"/n/home11/sambt/phlab-neurips25/runs/cifar10_simCLR_ResNet50_T0.1_withClassifier_dim4_exclude2/lightning_logs/rlzxkflo/checkpoints/epoch=5-step=528.ckpt\",\n",
    "    3:\"/n/home11/sambt/phlab-neurips25/runs/cifar10_simCLR_ResNet50_T0.1_withClassifier_dim4_exclude3/lightning_logs/wi6idr9q/checkpoints/epoch=5-step=528.ckpt\",\n",
    "    4:\"/n/home11/sambt/phlab-neurips25/runs/cifar10_simCLR_ResNet50_T0.1_withClassifier_dim4_exclude4/lightning_logs/nfmxrtyd/checkpoints/epoch=3-step=352.ckpt\",\n",
    "    5:\"/n/home11/sambt/phlab-neurips25/runs/cifar10_simCLR_ResNet50_T0.1_withClassifier_dim4_exclude5/lightning_logs/lhxchpq6/checkpoints/epoch=6-step=616.ckpt\",\n",
    "    6:\"/n/home11/sambt/phlab-neurips25/runs/cifar10_simCLR_ResNet50_T0.1_withClassifier_dim4_exclude6/lightning_logs/pvt7snek/checkpoints/epoch=2-step=264.ckpt\"\n",
    "}\n",
    "classes = sorted(list(checkpoints.keys()))\n",
    "\n",
    "models = {l:SimCLRModel.load_from_checkpoint(checkpoints[l]).to(device) for l in classes}\n",
    "outdirs = {}\n",
    "for label in classes:\n",
    "    outdir = f\"embeddings_noShift_spaceWithClassifier/cifar_excludeClass{label}/\"\n",
    "    os.makedirs(outdir,exist_ok=True)\n",
    "    outdirs[label] = outdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b8170dc-4033-4204-8f40-9d31c1784dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10p1_data = np.load(\"cifar10.1_data/cifar10.1_v6_data.npy\").transpose(0,3,1,2)\n",
    "cifar10p1_labels = np.load(\"cifar10.1_data/cifar10.1_v6_labels.npy\")\n",
    "shuf = np.random.permutation(len(cifar10p1_labels))\n",
    "cifar10p1_data = torch.tensor(cifar10p1_data[shuf])\n",
    "cifar10p1_labels = torch.tensor(cifar10p1_labels[shuf])\n",
    "transform = dutils.ResNet50Transform(resnet_type='resnet50',grayscale=False,from_pil=False)\n",
    "dataset = dutils.TransformDataset(transform,cifar10p1_data,cifar10p1_labels)\n",
    "loader = DataLoader(dataset,batch_size=512,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b908a2d9-ff9d-49b7-b1a1-00843019e2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:08<00:00,  2.16s/it]\n"
     ]
    }
   ],
   "source": [
    "embeds = {l:[] for l in classes}\n",
    "labels = {l:[] for l in classes}\n",
    "for batch in tqdm(loader):\n",
    "    x,labs = batch\n",
    "    for l in classes:\n",
    "        with torch.no_grad():\n",
    "            embeds[l].append(models[l].encoder(x.to(device)).cpu().numpy())\n",
    "        labels[l].append(labs.numpy())\n",
    "for l in classes:\n",
    "    np.savez(f\"{outdirs[l]}/cifar10.1.npz\",\n",
    "             data=np.concatenate(embeds[l]),\n",
    "             labels=np.concatenate(labels[l]))\n",
    "del embeds, labels\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7b6ad7-87bf-40af-a88e-1044103b3a30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mamba-torch_gpu]",
   "language": "python",
   "name": "conda-env-mamba-torch_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
